\section{From Principles to Practice: Implications for the Future of Software Engineering}
\label{sec:implications}

The four aforementioned principles provide a framework for evaluating incremental steps in research: \ie Does a proposed tool or practice make artifacts more structured, inspectable, reusable, or better governed? The principles are technology-agnostic---\allowbreak knowledge graphs, computational notebooks, and repositories are potential instantiations, but the principles describe \textit{properties} that artifacts should have, leaving room for diverse implementations. The challenge is designing systems and reforming incentives to make cumulative knowledge building not only possible but rewarded.Realizing these principles requires changes in how research is conducted, reviewed, published, and rewarded.

\subsection{Research Practice and Publication}

Research practice would shift toward documenting process alongside outcomes: recording methodological decisions, their rationales, and impacts using computational notebooks, version control, and workflow platforms. Researchers would supplement narrative papers with structured representations---semantic annotations or knowledge graph entries---making contributions directly accessible for synthesis. Designing for reuse would become standard: datasets documented with schemas, code modular and documented, protocols reproducible. Structured artifacts would enable new collaboration forms, with researchers contributing incrementally to shared knowledge bases rather than isolated papers.

Publication and review would need to value consolidation alongside novelty. Papers that resolve contradictions, curate benchmarks, or provide infrastructure should be recognized. These replications are critical to avoid contributing to the ``vast graveyard of undead theories'' for software research~\cite{ferguson2012vast}. As such, conferences should establish expectations for structured artifacts as first-class contributions, not optional supplements~\cite{nakagawa2024artifacts}. As one participant noted, replication studies are considered ``\textit{thankless volunteer work}'' and ``\textit{it is not sustainable for people to be doing these things well and frequently without proper incentives}'' (196051220). Replication efforts in other domains found only approximately one-third of published experiments in psychology (39/100)~\cite{open2015estimating} and economics (22/67)~\cite{chang2015economics} were able to effectively reproduce statistically significant results from the original studies. If artifacts evolve post-publication, papers become snapshots while living artifacts accumulate evidence and track refinements, requiring new norms for citing evolving work.

\subsection{Community Infrastructure}

The community would need platforms for storing, querying, and updating structured artifacts---knowledge graphs, benchmark repositories, collaborative platforms---maintained through community governance~\cite{atkins2003,keivanloo2022kgdev}. As one survey participant proposed: ``\textit{a shared repository for research ideas, datasets, and research materials that lead to better distribution, collaboration, and replication}'' (196181126). Shared standards (\eg ontologies, schemas, reporting protocols) would enable reuse across studies~\cite{wohlin2012}. Infrastructure contributions and replications would require recognition through alternative metrics or contribution-tracking platforms~\cite{allen2019}. Governance structures would manage stewardship: maintaining repositories, resolving disputes, and addressing ethical concerns. Without such infrastructure, the principles remain aspirational.

\subsection{FOSE as a Venue for Experimentation}

The Future of Software Engineering track could support experimentation with alternative artifact types: submissions experimenting with structured artifacts or living documents, judged on potential to demonstrate new knowledge-organizing approaches rather than solely novelty.

As a concrete example, consider a study finding automated code review reduces defects by 15\%. Under current norms, this paper is cited and superseded as its dataset ages. Under our principles, the group would register structured claims in a knowledge graph, link them to versioned data with provenance, and design for reuse. When contradictions emerge, structured representations enable diagnosing whether differences stem from datasets or methods---turning disputes into refinement. FOSE could welcome such experiments, building evidence for broader adoption.
