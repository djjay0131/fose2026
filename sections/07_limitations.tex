\section{Limitations and Open Questions}
\label{sec:limitations}

This paper offers a diagnosis of structural barriers to knowledge accumulation and a set of principles for future research artifacts. But it does not provide solutions, nor does it claim that realizing these principles will be straightforward. In this section, we acknowledge limitations of our approach and identify open questions that require further investigation.

\subsection{Limitations of the Survey Data}

Our analysis draws on responses from the ICSE 2026 FOSE pre-survey. While these data provide valuable community perspectives, they have limitations.

\textbf{Scope and representativeness.} The survey captured 280 responses, representing a small fraction of the global software engineering research community. Respondents self-selected, which may introduce bias: those who chose to respond may have stronger opinions or greater engagement with meta-research questions than the broader population. We cannot claim that the findings generalize to all researchers or all subfields within software engineering.

\textbf{Descriptive, not causal.} We use survey data to establish that the community is experienced, productive, and globally distributed. This supports our argument that accumulation challenges are structural rather than due to lack of expertise. But the survey data do not establish causation, nor do they provide direct evidence for the specific breakdowns we diagnose. Our diagnosis is interpretive, grounded in the data but also informed by broader observations and prior work.

\textbf{Snapshot in time.} The survey reflects perspectives at a particular moment. Community concerns and priorities evolve. What is salient in 2026 may differ from what was salient a decade ago or what will be salient a decade hence. Our findings should be understood as contextual, not universal.

\subsection{Generality Versus Specificity}

The principles we articulate are intentionally abstract, describing properties that future artifacts should have without prescribing specific implementations. This generality has both strengths and weaknesses.

\textbf{Strengths.} Technology-agnostic principles allow for diverse implementations across subfields and research communities. They provide a framework for evaluating proposals without committing to any single approach. They avoid the risk of advocating for tools or platforms that may become obsolete.

\textbf{Weaknesses.} Abstract principles can be difficult to operationalize. How does one know when an artifact is ``sufficiently structured'' or ``adequately provenance-aware''? Without concrete instantiations, principles may be too vague to guide action. Moreover, the tension between generality and specificity risks either being so broad as to be unhelpful or so narrow as to exclude valid alternatives.

We have attempted to balance this tension by providing illustrative examples alongside each principle. But translating principles into practice will require experimentation, iteration, and community deliberation.

\subsection{Feasibility and Adoption Challenges}

Even if the principles are sound, realizing them faces practical challenges.

\textbf{Effort and resources.} Producing structured, provenance-aware, long-lived artifacts requires effort. Researchers already face time pressures, competing priorities, and limited resources. Asking them to invest more in documentation, structuring, and curation may be unrealistic without corresponding reductions in other demands or increases in support.

\textbf{Infrastructure gaps.} The infrastructure needed to support cumulative knowledge building---shared repositories, standards, governance processes---does not yet exist in many areas of software engineering. Building it requires sustained investment, coordination, and institutional commitment. It is unclear where this investment will come from or how coordination will be achieved.

\textbf{Incentive misalignment.} Even with infrastructure in place, adoption depends on incentives. If tenure and promotion decisions continue to prioritize novel papers over infrastructure contributions, researchers will have little reason to invest in cumulative building. Changing incentives requires action at multiple levels: funding agencies, universities, conferences, and journals. Coordination across these actors is difficult.

\textbf{Cultural inertia.} Research communities have established norms and practices. Changing them requires not only technical solutions and policy reforms but also shifts in culture and expectations. Such shifts take time and may face resistance from those who succeed under current systems.

We do not underestimate these challenges. But acknowledging them is a first step toward addressing them.

\subsection{Ethical and Social Considerations}

Structured knowledge infrastructures raise ethical and social questions that we have not fully addressed.

\textbf{Ownership and control.} Who owns shared knowledge bases? Who decides what is included, updated, or removed? Centralized control risks gatekeeping and exclusion. Distributed control risks fragmentation and inconsistency. Finding governance models that balance these concerns is an open problem.

\textbf{Bias and fairness.} Knowledge artifacts reflect the data, assumptions, and priorities of their creators. If those creators are not diverse, the artifacts may perpetuate biases. Ensuring that knowledge infrastructures are inclusive, representative, and fair requires ongoing attention and deliberate effort.

\textbf{Access and equity.} Building and maintaining infrastructure requires resources. If these resources are concentrated in well-funded institutions or regions, the benefits may accrue unevenly. Ensuring equitable access to shared infrastructures and equitable participation in their governance is critical but not straightforward.

\textbf{Privacy and consent.} Structured artifacts may involve data about research processes, collaborations, or individuals. Ensuring that such data are used ethically, with appropriate consent and privacy protections, is essential.

These are not purely technical issues. They require community deliberation, ethical oversight, and ongoing stewardship. We do not claim to have answers, but we emphasize that any future infrastructure must address these concerns.

\subsection{Open Research Questions}

Beyond the limitations above, several open questions remain:

\begin{itemize}
\item \textbf{What forms of structure are most useful?} Different subfields may benefit from different representational frameworks. How do we balance standardization (for interoperability) with flexibility (for domain-specific needs)?

\item \textbf{How do we evaluate progress?} If artifacts evolve over time, how do we measure whether they are improving? What metrics indicate successful cumulative building versus fragmentation or stagnation?

\item \textbf{What governance models work best?} Centralized, federated, or fully distributed? Community-driven or institution-led? Different models have different trade-offs, and the optimal choice may vary by context.

\item \textbf{How do we transition from current practices?} Incremental adoption is likely more feasible than wholesale replacement. But what incremental steps are most effective? How do we avoid creating parallel systems that fragment the community further?

\item \textbf{What role should automation play?} Tools like large language models could potentially help structure knowledge, extract claims, or track provenance. But they also introduce risks of error, bias, and over-reliance on automation. How do we balance human oversight with scalable automation?
\end{itemize}

These questions do not have easy answers. They will require empirical investigation, experimentation, and ongoing community dialogue.

\subsection{Reflections on Scope}

Finally, we acknowledge that this paper focuses on structural and infrastructural challenges. We do not address all barriers to cumulative progress. Individual researcher behavior, institutional policies, funding priorities, and broader societal factors all play roles. Structural changes alone will not suffice if researchers are not motivated to adopt new practices, if institutions do not reward infrastructure contributions, or if funding does not support long-term knowledge-building efforts.

Our goal is not to provide a complete solution but to articulate one important dimension of the challenge: the design of research artifacts and the infrastructures that support them. We hope this diagnosis and these principles can inform broader efforts to make software engineering research more cumulative, transparent, and impactful.
