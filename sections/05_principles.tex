\section{Rethinking Research Artifacts for Cumulative Progress}
\label{sec:principles}

The structural barriers trace back to design choices in how research artifacts are produced and shared. By \textit{research artifacts} we mean the tangible outputs of research: papers, datasets, code repositories, benchmarks, computational notebooks, knowledge graphs, and experimental protocols. These artifacts are vessels for knowledge. They encode claims, evidence, methodological context, and the provenance of results. How well knowledge accumulates depends on their properties: whether claims can be extracted, evidence traced, artifacts reused beyond publication, and communities can build on prior work.

Addressing these barriers means reconsidering artifact properties. We propose four technology-agnostic principles. Implementations will vary, but these principles provide a shared foundation for evaluating research infrastructure.

\subsection{Principle 1: Structured and Interpretable}

\textbf{Principle:} Research artifacts should make claims, evidence, and context explicit and directly accessible, not just embedded in prose.

The first breakdown, papers as isolated units, stems from claims and evidence being woven into narrative text. Prose works well for explaining motivation, but it is not ideal for cumulative synthesis. Comparing claims across papers means reading entire documents and reconciling terminology. This does not scale as the literature grows.

Artifacts should represent claims, evidence, and context as structured, first-class entities. A claim should be identifiable: ``Technique X improves metric Y on dataset Z by $\delta$ under conditions C.'' Evidence and context should be explicitly linked, not buried in prose. Structured representations let conflicting claims become visible and resolvable by examining evidence directly. Claims referencing updated datasets can be systematically reevaluated. Examples include semantic annotations (machine-readable metadata describing claims and results) or knowledge graphs~\cite{orkg,wang2020,stocker2024orkg,wang2023kg} (entities with typed relationships enabling queries like ``Which papers claim improvements on dataset D?''). Structure complements prose, making knowledge directly accessible while preserving narrative's explanatory power.

\subsection{Principle 2: Inspectable and Provenance-Aware}

\textbf{Principle:} Research artifacts should preserve the full provenance of claims, from raw data through methodological decisions to final results, and make this provenance inspectable (accessible and understandable by researchers who want to examine, verify, or build on the work).

The second breakdown, loss of context and provenance, occurs because reasoning behind decisions fades as knowledge moves through publication. Papers report final results but often omit the path taken: why this dataset, baseline, or protocol. Later researchers must reconstruct this reasoning, often discovering that subtle choices significantly impacted results.

Artifacts should document not just what was found but how and why. Every claim should trace to its sources: data, code, configuration, assumptions. Methodological decisions should be explicitly justified. When results are updated, the provenance chain should track changes~\cite{gonzalez-barahona2012}. Provenance enables trust: researchers can inspect a claim's lineage, verify evidence, and understand conditions. When claims conflict, provenance helps diagnose divergence. Examples include versioned computational artifacts (code and data in version control with clear lineage) or provenance graphs (explicit representations linking claims to experiments to data).

\subsection{Principle 3: Long-Lived and Reusable}

\textbf{Principle:} Research artifacts should support evolution and reuse, not remain static at publication.

Papers are snapshots frozen in time. Once published, they rarely update when new evidence emerges, datasets are revised, or methods improve. Follow-on work cites and describes differences in prose, but original claims remain unchanged. Research artifacts are also often hard to reuse. Prior efforts to replicate research systems from ICSE and FSE tool demonstration tracks succeeded in running only about half (76/131), despite thousands of hours of effort~\cite{murphyhill-reviving}.

Artifacts should be living substrates that can be updated, extended, and reused. When datasets are corrected, dependent claims should be re-evaluable. When techniques are refined, prior results should be comparable. This does not mean rewriting papers. Instead, underlying structured representations decouple from narrative documents. Narratives remain stable as historical records while structured substrates evolve. Examples include living knowledge bases (repositories where claims and datasets are versioned and updated) or executable benchmarks (evaluation frameworks rerun with updated data). Knowledge should outlive individual papers, accumulating in shared substrates.

\subsection{Principle 4: Governed with Human Oversight}

\textbf{Principle:} Research artifacts and infrastructures should be governed by community processes ensuring quality, integrity, and ethical responsibility.

Even with perfect technical infrastructure, cumulative progress requires coordination: quality standards, conflict resolution, and recognition for consolidation work. Artifacts cannot govern themselves. Structured representations and provenance tracking are valuable only if the community trusts, maintains, and uses them responsibly. This requires human oversight: peer review for knowledge contributions, curation, dispute resolution, and credit systems valuing infrastructure work alongside novel research. The human-artifact model suggests human expertise is necessary to understand artifacts within broader ecosystems and motivate future designs~\cite{b2011human}.

Governance also addresses ethical concerns: ownership, attribution, bias, and access. Who controls shared knowledge bases? How is credit assigned for incremental contributions? How do we prevent infrastructures from perpetuating biases? These questions require community deliberation and ongoing stewardship. Examples include community curation processes (peer-reviewed contributions with clear criteria) or credit systems recognizing infrastructure, replication, and consolidation work. Cumulative progress is a collective endeavor; technical solutions must be embedded in social practices that align individual incentives with collective goals.

% \subsection{From Principles to Practice}

% These principles are aspirational, requiring significant changes in how research is conducted, reviewed, and rewarded. They provide a framework for evaluating incremental steps: Does a proposed tool or practice make artifacts more structured, inspectable, reusable, or better governed? The principles are technology-agnostic---\allowbreak knowledge graphs, computational notebooks, and repositories are potential instantiations, but the principles describe \textit{properties} that artifacts should have, leaving room for diverse implementations. The challenge is designing systems and reforming incentives to make cumulative knowledge building not only possible but rewarded.
