\section{Where Knowledge Accumulation Breaks Down}
\label{sec:breakdown}

If the community is experienced, productive, and global, yet still struggles to synthesize results and build on prior work, the barriers are structural. We identify four interrelated breakdowns in how research artifacts are produced, represented, and connected. Anonymous participant identifiers appear in parentheses.

\subsection{Papers as Isolated Knowledge Units}

Research papers package claims, evidence, and context into narrative prose optimized for dissemination. This works well for presenting new ideas but creates barriers to cumulative building. One participant noted that ``\textit{15 years ago [it was the norm to] present and discuss a research idea at a workshop then go back home, build and evaluate the thing, then publish at a conference. These days, reviewers repeatedly reject such submissions `because the work has already appeared at this and that workshop'}'' (195811076). Claims get buried in paragraphs alongside motivation and methods. Extracting and comparing claims across papers means reading entire documents and reconciling different terminology. Evidence linkages stay implicit; readers infer which results support which claims under what assumptions. Even when artifacts are shared, results freeze at publication time. Updates to datasets or baselines require new papers, while original claims sit unchanged. As another participant observed, ``\textit{despite having a software artifact track, not many of the software artifacts are being actively maintained}'' (196030130). Each paper becomes an island connected only through citations and prose, requiring manual synthesis that does not scale.

\subsection{Loss of Context and Provenance}

Research involves countless contextual decisions: which dataset, how to split data, which baselines, how to handle edge cases. Papers describe these choices but often omit the rationale. One participant noted frustration with ``\textit{software engineering researchers trying to do research with generative AI tools without specifying context first}'' (196032564). As work gets cited and summarized, motivation and assumptions fade. Carefully qualified findings become unqualified facts in subsequent literature. Methodological decisions must be reverse-engineered, sometimes revealing that subtle choices significantly impacted results. Papers present polished final versions, hiding the path from hypothesis to result. When context and provenance are lost, later researchers either accept prior work at face value or invest substantial effort reconstructing the reasoning. Moreover, despite goals to enhance practice, research has ``\textit{minimal}'' and ``\textit{almost no relevance}'' to industry contexts (192101946).

\subsection{Claims Evolve Without Tracking}

Scientific claims get refined, qualified, contradicted, and superseded as evidence accumulates, but the publication system provides few tracking mechanisms. The literature may contain conflicting claims (technique A outperforms B in one paper, the reverse in another) without systematic flagging. Survey respondents noted that ``\textit{most of the SE research being published is neither reproducible nor replicable}'' (195853386) and ``\textit{we are reluctant to accept papers that replicate previous study...see medical sciences as counter example - they publish single cases as they allow to build body of konowledge in the long run}'' (196067582). When researchers discover conflicts, they must investigate causes themselves, often finding subtle methodological differences explain the divergence. Refinements stay implicit: a follow-on paper may qualify a prior claim, but the original remains unchanged. Claim relationships (does one extend, contradict, or depend on another?) appear only in natural language like "building on [12]" or "in contrast to [34]." Without structured representations, determining what is currently believed, under what conditions, and with what confidence requires extensive manual synthesis.

\subsection{Incentive Structures Favor Novelty Over Accumulation}

The final breakdown is embedded in incentive structures. Publication venues, hiring criteria, and funding mechanisms reward novelty~\cite{nosek2012,smaldino2016}. Conference and journal reviews prioritize new techniques; replication studies, negative results, and syntheses face higher acceptance bars even when they would advance collective understanding~\cite{basili1999}. Researchers investing in replication or shared infrastructure face opportunity costs: these efforts may not yield top-venue publications or count in promotion reviews~\cite{collberg2016}. One participant stated ``\textit{we are not good at replication (despite better rigour in what we do)...too much effort goes into chasing `new' rather than consolidating our knowledge}'' (192758693). Building knowledge repositories and interoperability layers requires sustained effort, often led by small groups without commensurate recognition. Everyone benefits from better infrastructure, but individuals face little incentive to contribute. As long as novelty is privileged over accumulation, knowledge stays fragmented. \\

These four breakdowns reinforce one another. Incremental fixes (better citation practices, more replications, improved repositories) help but are not enough. Addressing these barriers requires rethinking the fundamental properties of research artifacts themselves.
