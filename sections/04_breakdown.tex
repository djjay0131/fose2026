\section{Where Knowledge Accumulation Breaks Down}
\label{sec:breakdown}

If the software engineering community is experienced, productive, and globally distributed, yet faces persistent challenges synthesizing results and building on prior work, then the barriers must be structural. We diagnose four interrelated breakdowns arising from how research artifacts are currently produced, represented, and connected. For extracted quotes, anonymous participant identifiers are presented in parentheses.

\subsection{Papers as Isolated Knowledge Units}

Research papers package claims, evidence, and context into narrative prose optimized for dissemination. While effective for presenting new ideas, this format creates barriers to cumulative building. For instance, participants responded that aspects of the software engineering research community that are not working well include: ``\textit{15 years ago [it was the norm to] present and discuss a research idea at a workshop then go back home, build and evaluate the thing, then publish at a conference. These days, reviewers repeatedly reject such submissions `because the work has already appeared at this and that workshop'}'' (195811076). Claims are embedded in paragraphs, interleaved with motivation and methods, making extraction and comparison across papers require reading entire documents and reconciling terminological differences. Evidence linkages remain implicit---readers must infer which results support which claims under what assumptions. Even when artifacts are shared, results are static at publication time; updates to datasets or baselines require new papers citing the old, while original claims remain unchanged. As one participant noted, ``\textit{despite having a software artifact track, not many of the software artifacts are being actively maintained}'' (196030130). The consequence is fragmentation: each paper is an island connected only through citations and prose, requiring repeated manual synthesis that does not scale as literature grows.

\subsection{Loss of Context and Provenance}

Research involves countless contextual decisions: which dataset to use, how to split data, which baselines to compare, how to handle edge cases. Papers describe these choices but often omit the rationale due to space constraints. For instance, one participant found stress in ``\textit{software engineering researchers trying to do research with generative AI tools without specifying context first}'' (196032564). As work is cited and summarized, motivation and assumptions fade---carefully qualified findings become unqualified facts in subsequent literature. Methodological decisions must be reverse-engineered, sometimes revealing that subtle choices significantly impacted results. Papers present polished final versions, hiding the evolutionary path from hypothesis to result. When context and provenance are lost, later researchers must either accept prior work at face value or invest substantial effort reconstructing reasoning, slowing progress and increasing misapplication risk. Moreover, despite goals to enhance development in practice, research has ``\textit{minimal}'' and ``\textit{almost no relevance}'' to industry contexts (192101946). 

\subsection{Claims Evolve Without Tracking}

Scientific claims are refined, qualified, contradicted, and superseded as evidence accumulates, yet the publication system provides limited tracking mechanisms. The literature may contain conflicting claims---technique A outperforms B in one paper, the reverse in another---but contradictions are not systematically flagged. As survey respondents mentioned, ``\textit{most of the SE research being published is neither reproducible nor replicable}'' (195853386) and ``\textit{we are reluctant to accept papers that replicate previous study...see medical sciences as counter example - they publish single cases as they allow to build body of konowledge in the long run}'' (196067582). Researchers discovering conflicts must investigate causes themselves, often finding subtle methodological differences account for divergence. Refinements are implicit: a follow-on paper may qualify a prior claim, but the original remains unchanged. Claim relationships---does one extend, contradict, or depend on another?---are expressed only in natural language like "building on [12]" or "in contrast to [34]". Without structured representations, knowledge remains fragmented and ambiguous, requiring extensive manual synthesis to determine what is currently believed, under what conditions, and with what confidence.

\subsection{Incentive Structures Favor Novelty Over Accumulation}

The final breakdown is embedded in incentive structures. Publication venues, hiring criteria, and funding mechanisms reward novelty and originality~\cite{nosek2012,smaldino2016}. Conference and journal reviews prioritize new techniques and findings; replication studies, negative results, and syntheses face higher acceptance bars even when they would advance collective understanding~\cite{basili1999}. Researchers investing in replication, dataset curation, or shared infrastructure face opportunity costs---these efforts may not yield top-venue publications or count heavily in promotion reviews~\cite{collberg2016}. Participants highlighted this as a weakness in the software engineering community, with one stating ``\textit{we are not good at replication (despite better rigour in what we do)...too much effort goes into chasing `new' rather than consolidating our knowledge}'' (192758693). Building knowledge repositories, ontologies, and interoperability layers requires sustained effort often led by small groups without commensurate recognition. The result is a collective action problem: everyone benefits from better infrastructure, but individuals are disincentivized from contributing. As long as novelty is privileged over accumulation, knowledge remains fragmented and progress constrained. \\

These four breakdowns reinforce one another, creating a system where knowledge accumulates slowly despite increased community expertise and productivity. Incremental fixes---better citation practices, more replications, improved repositories---are necessary, but insufficient. Addressing these barriers requires rethinking the fundamental properties of research artifacts themselves.
